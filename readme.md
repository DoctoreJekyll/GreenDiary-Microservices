# üå± Plant Diary ‚Äî Microservicios (README)

Este README es **una gu√≠a completa y √∫nica** para levantar, desarrollar y depurar el proyecto "Plant Diary" (microservicios: plant, watering, auth, gateway, discovery) con Kafka, Postgres y Docker Compose.

---

# √çndice

1. Descripci√≥n breve
2. Arquitectura (qu√© hace cada servicio)
3. Tecnolog√≠as
4. Estructura del repositorio
5. Requisitos previos
6. Construcci√≥n (jar + docker)
7. Docker Compose (levantar todo)
8. Variables de entorno importantes / c√≥mo configurar
9. Kafka: crear topics y probar con console-producer/consumer
10. Flujo de eventos sugerido y ejemplos JSON
11. Pruebas (curl / Postman ejemplos)
12. Errores habituales y soluciones r√°pidas
---

# 1) Descripci√≥n

Aplicaci√≥n compuesta por microservicios para llevar un diario de plantas: registrar plantas, guardar riegos (historico), autenticaci√≥n con JWT, comunicaci√≥n s√≠ncrona (REST) y asincr√≥nica (Kafka). Est√° pensada para ser reproducible localmente con Docker Compose.

---

# 2) Arquitectura

* **Discovery (Eureka)** ‚Äî registro de instancias
* **API Gateway** ‚Äî entrada unificada (reescribe path hacia /api/xxx)
* **Plant Service** ‚Äî CRUD de plantas + consumidor Kafka (actualiza lastWatered)
* **Watering Service** ‚Äî CRUD de riegos + productor Kafka (emite evento cuando se crea un riego)
* **Auth Service** ‚Äî login/register + gesti√≥n usuarios y roles
* **Kafka + Zookeeper** ‚Äî mensajer√≠a as√≠ncrona
* **Postgres** ‚Äî bases de datos por microservicio (plantdb, wateringdb, authdb)

Topolog√≠a simplificada:

```
Client -> Gateway (8080) -> (via Eureka) -> Plant (8081) / Watering (8082) / Auth (8084)
                       \-> Kafka (9092) -> topics -> Plant consumer / otros
```

---

# 3) Tecnolog√≠as

* Java 21, Spring Boot 3.x
* Spring Cloud (Feign, Gateway, Eureka)
* Spring Security (JWT)
* Spring Kafka
* PostgreSQL
* Docker, Docker Compose
* Maven

---

# 4) Estructura del repositorio (sugerida)

```
/ (ra√≠z)
  docker-compose.yml
  /plant-service
    Dockerfile
    pom.xml
    src/...
  /watering-service
    Dockerfile
    pom.xml
    src/...
  /auth-service
  /gateway-service
  /discovery-service
  /common-lib  (artefacto java compartido: DTOs, excepciones)
```

`common-lib` es una librer√≠a compartida: **no** es un servicio, sino un m√≥dulo que compilas con Maven para que los otros servicios lo consuman en tiempo de compilaci√≥n.

---

# 5) Requisitos previos (local sin Docker)

* Java 21 y Maven (si quieres compilar jars antes de docker)
* Docker Desktop (o Docker Engine) + Docker Compose

---

# 6) Construcci√≥n local (jars)

Desde la ra√≠z del repo (si es multi-m√≥dulo):

```bash
mvn clean package -DskipTests
```

* Esto genera `target/*.jar` en cada microservicio. Si ves `no main manifest attribute, in app.jar` significa que no generaste el jar correcto (ejecuta `mvn package`).

---

# 7) Docker: build & up (todo el stack)

**1) Opcional**: construir im√°genes si en Dockerfile haces COPY de `target/*.jar` (recomendado):

```bash
# desde la ra√≠z, si tus Dockerfiles usan COPY target/*.jar
mvn clean package -DskipTests
```

**2) Construir im√°genes y levantar**

```bash
# build y levantado (desde la ra√≠z con docker-compose.yml)
docker compose build
# arrancar en background
docker compose up -d
# ver contenedores
docker compose ps
# ver logs
docker compose logs -f
```

**NOTA importante sobre hosts**

* Dentro de Docker Compose, los servicios se ven por nombre de servicio (p. ej. `kafka:9092`, `plant-db:5432`).
* Desde tu host (Postman, navegador) usas `localhost` y los puertos mapeados (ej. `localhost:8080` para gateway).

---

# 8) Variables y application.yml ‚Äî c√≥mo mapearlas en docker-compose

En tu `docker-compose.yml` pasar√°s variables que overridean `application.yml` usando `SPRING_` env vars. Ejemplos (tu compose ya tiene estos):

```yaml
environment:
  SPRING_DATASOURCE_URL: jdbc:postgresql://plant-db:5432/plantdb
  SPRING_DATASOURCE_USERNAME: plantuser
  SPRING_DATASOURCE_PASSWORD: plantpass
  SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka:9092
  EUREKA_CLIENT_SERVICEURL_DEFAULTZONE: http://discovery:8761/eureka
```

En `application.yml` de cada servicio deja una propiedad por defecto, pero permite override con env vars:

```yaml
spring:
  datasource:
    url: ${SPRING_DATASOURCE_URL:jdbc:postgresql://localhost:5433/plantdb}
  kafka:
    bootstrap-servers: ${SPRING_KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
```

**Recuerda:** cuando los servicios corren dentro del mismo compose, `bootstrap-servers` debe ser `kafka:9092`. Si pruebas desde tu host, `localhost:9092`.

---

# 9) Kafka ‚Äî crear topic y probar

**Crear topic (ejecutarlo cuando kafka est√© listo)**

Windows / PowerShell: ejecuta en una l√≠nea (evita el uso de `\` multil√≠nea):

```powershell
docker exec -it kafka bash -c "kafka-topics --create --bootstrap-server localhost:9092 --topic plant-events --partitions 1 --replication-factor 1"
```

Linux/macOS (o WSL):

```bash
docker exec -it kafka bash -c 'kafka-topics --create --bootstrap-server localhost:9092 --topic plant-events --partitions 1 --replication-factor 1'
```

**Consumir todo el topic (desde el inicio)**

```bash
docker exec -it kafka bash -c "kafka-console-consumer --bootstrap-server localhost:9092 --topic plant-events --from-beginning"
```

**Producir mensajes manualmente**

```bash
docker exec -it kafka bash -c "kafka-console-producer --broker-list localhost:9092 --topic plant-events"
# luego escribe JSON en la consola
```

**Notas sobre errores que viste antes**

* `LEADER_NOT_AVAILABLE`: Kafka a√∫n no ha electo un l√≠der para la partici√≥n. Espera 5-10s y vuelve a crear/consumir. Si persiste, revisa `KAFKA_ADVERTISED_LISTENERS` y que el contenedor kafka est√© realmente UP.
* `kafka-console-consumer : El t√©rmino 'kafka-console-consumer' no se reconoce...`: en PowerShell no tienes las binarios localmente: usa `docker exec -it kafka bash -c "kafka-console-consumer ..."` para ejecutarlo dentro del contenedor.

---

# 10) Flujo de eventos sugerido (ejemplo pr√°ctico)

**Tipo de eventos** (ejemplos):

* `PLANT_CREATED` ‚Äî cuando se crea una planta
* `PLANT_UPDATED` ‚Äî cambios en la planta
* `WATERING_CREATED` ‚Äî nuevo riego (lo usar√° plant-service para actualizar lastWatered)
* `WATERING_DELETED` ‚Äî opcional

**Ejemplo JSON para `WATERING_CREATED`**

```json
{
  "eventType": "WATERING_CREATED",
  "plantId": 5,
  "owner": "jose",
  "wateredAt": "2025-09-25T17:45:00"
}
```

**Productor (WateringService)**

* Despu√©s de `save()` del riego, produce el evento al topic `plant-events`.
* Usa `JsonSerializer` para el `value`.

**Consumidor (PlantService)**

* `@KafkaListener(topics = "plant-events")` recibe eventos.
* Si `eventType == WATERING_CREATED` ‚Üí llama m√©todo que actualiza `plants.lastWatered` con `wateredAt` del evento.

---

# 11) Snippets de c√≥digo (configuraci√≥n r√°pida)

**application.yml (kafka producer/consumer)**

```yaml
spring:
  kafka:
    bootstrap-servers: ${SPRING_KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
    consumer:
      group-id: plant-service
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring.json.trusted.packages: '*'
```

**Producer Java (simplificado)**

```java
@Service
public class PlantEventProducer {
  private final KafkaTemplate<String, Object> kafka;
  public PlantEventProducer(KafkaTemplate<String, Object> kafka) { this.kafka = kafka; }
  public void send(String topic, Object event) {
    kafka.send(topic, event).addCallback();
  }
}
```

**Consumer Java (simplificado)**

```java
@Service
public class PlantEventConsumer {
  private final PlantService plantService;
  @KafkaListener(topics = "plant-events", groupId = "plant-service")
  public void listen(PlantEvent event) {
    if ("WATERING_CREATED".equals(event.getEventType())) {
      plantService.updateLastWatered(event.getPlantId(), event.getWateredAt());
    }
  }
}
```

---

# 12) Pruebas: curl / Postman ejemplos

**Login (Auth)**

```bash
POST http://localhost:8080/auth/login
Content-Type: application/json
{
  "username":"jose",
  "password":"password"
}
```

**Crear planta (via Gateway)**

```bash
POST http://localhost:8080/plants
Authorization: Bearer <token>
Content-Type: application/json
{
  "name":"Ficus",
  "species":"Ficus elastica",
  "location":"Salon"
}
```

**Crear riego (via Gateway)**

```bash
POST http://localhost:8080/plants/5/watering
Authorization: Bearer <token>
Content-Type: application/json
{
  "wateringDate":"2025-09-25T17:45:00",
  "notes":"Regado por la tarde"
}
```

Despu√©s de crear riego deber√≠as ver en el consumidor (o en consola kafka-console-consumer) el JSON del evento.

---

# 13) Errores comunes y soluciones r√°pidas

* `no main manifest attribute, in app.jar` ‚Üí compilaci√≥n Maven no gener√≥ JAR correcto. Ejecuta `mvn clean package`.
* `relation "users" does not exist` ‚Üí la tabla no existe a√∫n: revisa `ddl-auto` (en dev usa `update` o ejecuta `data.sql`) y que la DB se haya inicializado correctamente.
* `duplicate key value violates unique constraint` al ejecutar `data.sql` ‚Üí usa `INSERT ... WHERE NOT EXISTS` o `ON CONFLICT DO NOTHING` para evitar recrear entradas.
* Kafka `LEADER_NOT_AVAILABLE` ‚Üí espera que kafka termine de arrancar o revisa `KAFKA_ADVERTISED_LISTENERS`.
* `Couldn't resolve server kafka:9092` desde host: tu app dentro de docker debe usar `kafka:9092`. Desde anfitri√≥n (host) usa `localhost:9092`.

---
